{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import helper_functions\n",
    "from helper_functions import split_into_sentences, unstack_listcol, count_alpha\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading in the review data from feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                                         reviewText  overall\n",
      "0          1  My daughter wanted this book and the price on ...      5.0\n",
      "1          2  I bought this zoku quick pop for my daughterr ...      5.0\n",
      "2          3  There is no shortage of pop recipes available ...      4.0\n",
      "3          4  This book is a must have if you get a Zoku (wh...      5.0\n",
      "4          5  This cookbook is great.  I have really enjoyed...      4.0\n"
     ]
    }
   ],
   "source": [
    "PATH = \"../../../Dropbox/RA/stefano_coffeemachines/amazon_reviews/\"\n",
    "df = pd.read_feather(f'{PATH}reviews_Home_and_Kitchen_5-raw')\n",
    "df.shape\n",
    "# let's take 100 reviews\n",
    "df = df.iloc[:100]\n",
    "df['review_id'] = np.arange(df.shape[0])+1\n",
    "cols = ['review_id', 'reviewText', 'overall']\n",
    "df = df[cols]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Sentiment analysis on the full reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id                                         reviewText  overall  \\\n",
      "0          1  My daughter wanted this book and the price on ...      5.0   \n",
      "1          2  I bought this zoku quick pop for my daughterr ...      5.0   \n",
      "2          3  There is no shortage of pop recipes available ...      4.0   \n",
      "3          4  This book is a must have if you get a Zoku (wh...      5.0   \n",
      "4          5  This cookbook is great.  I have really enjoyed...      4.0   \n",
      "\n",
      "     pos    neu    neg    comp  \n",
      "0  0.270  0.730  0.000  0.8625  \n",
      "1  0.233  0.767  0.000  0.7906  \n",
      "2  0.162  0.782  0.056  0.9949  \n",
      "3  0.178  0.822  0.000  0.9022  \n",
      "4  0.249  0.712  0.039  0.9750  \n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['sentdict'] = df.apply(lambda row: analyzer.polarity_scores(row['reviewText']), axis = 1)\n",
    "df['pos'] = df.apply(lambda row: row['sentdict']['pos'], axis = 1)\n",
    "df['neu'] = df.apply(lambda row: row['sentdict']['neu'], axis = 1)\n",
    "df['neg'] = df.apply(lambda row: row['sentdict']['neg'], axis = 1)\n",
    "df['comp'] = df.apply(lambda row: row['sentdict']['compound'], axis = 1)\n",
    "\n",
    "df = df.drop(['sentdict'], axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Sentiment analysis on sentence-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['pos', 'neg', 'neu', 'comp'], axis = 1)\n",
    "\n",
    "# splitting the text column into sentences\n",
    "df['sentence'] = df.apply(lambda row: split_into_sentences(row['reviewText']), axis=1)\n",
    "# unstacking the list column\n",
    "a = unstack_listcol(df, 'sentence')\n",
    "\n",
    "# removing non-ascii characters\n",
    "a.sentence.replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "\n",
    "# keeping only sentences with at least one alphabetic character\n",
    "a['nalpha'] = a.apply(lambda row: count_alpha(row['sentence']), axis = 1)\n",
    "a = a.loc[a['nalpha'] >= 1]\n",
    "\n",
    "# keeping only sentences with length >= 2\n",
    "a['sentlen'] = a.apply(lambda row: len(row['sentence']), axis = 1)\n",
    "a = a.loc[a['sentlen'] >= 2]\n",
    "\n",
    "# removing some columns\n",
    "a = a.drop(columns = ['nalpha', 'sentlen', 'reviewText'], axis=1)\n",
    "\n",
    "# adding a sentence id column\n",
    "a = a.reset_index()\n",
    "ncols = len(a.columns)\n",
    "a.insert(ncols-1, 'sentence_id', 0)\n",
    "a['sentence_id'] = a.index + 1\n",
    "\n",
    "# remove the index column\n",
    "a = a.drop(columns = ['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_id  overall  sentence_id  \\\n",
      "0          1      5.0            1   \n",
      "1          1      5.0            2   \n",
      "2          1      5.0            3   \n",
      "3          2      5.0            4   \n",
      "4          2      5.0            5   \n",
      "\n",
      "                                            sentence    pos    neu  neg  \\\n",
      "0  My daughter wanted this book and the price on ...  0.349  0.651  0.0   \n",
      "1  She has already tried one recipe a day after r...  0.000  1.000  0.0   \n",
      "2                           She seems happy with it.  0.481  0.519  0.0   \n",
      "3  I bought this zoku quick pop for my daughterr ...  0.000  1.000  0.0   \n",
      "4  She loves it and have fun to make her own ice ...  0.412  0.588  0.0   \n",
      "\n",
      "     comp  \n",
      "0  0.7096  \n",
      "1  0.0000  \n",
      "2  0.5719  \n",
      "3  0.0000  \n",
      "4  0.7906  \n",
      "(417, 8)\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "a['sentdict'] = a.apply(lambda row: analyzer.polarity_scores(row['sentence']), axis = 1)\n",
    "a['pos'] = a.apply(lambda row: row['sentdict']['pos'], axis = 1)\n",
    "a['neu'] = a.apply(lambda row: row['sentdict']['neu'], axis = 1)\n",
    "a['neg'] = a.apply(lambda row: row['sentdict']['neg'], axis = 1)\n",
    "a['comp'] = a.apply(lambda row: row['sentdict']['compound'], axis = 1)\n",
    "\n",
    "a = a.drop(['sentdict'], axis = 1)\n",
    "print(a.head())\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                pos       neu       neg      comp\n",
      "review_id                                        \n",
      "1          0.276667  0.723333  0.000000  0.427167\n",
      "2          0.206000  0.794000  0.000000  0.395300\n",
      "3          0.147000  0.808923  0.044115  0.217535\n",
      "4          0.165000  0.835000  0.000000  0.337680\n",
      "5          0.341000  0.632125  0.026875  0.424013\n",
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "a = a.groupby(['review_id']).agg({'pos':'mean', 'neu':'mean', 'neg':'mean', 'comp':'mean'})\n",
    "print(a.head())\n",
    "print(a.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
